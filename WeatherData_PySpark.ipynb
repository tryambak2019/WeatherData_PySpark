{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Row, Window\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "from datetime import date\n",
    "import tarfile\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Spark context with Spark configuration\n",
    "conf = SparkConf().setAppName(\"Paytm Solution - Python\").set(\n",
    "    \"spark.hadoop.yarn.resourcemanager.address\", \"192.168.0.104:8032\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# sc.stop()\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Paytm Soln\").config(\n",
    "    \"spark.some.config.option\", \"some-value\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Setting Up the Data\n",
    "\n",
    "1. Load the global weather data into your big data technology of choice.\n",
    "2. Join the stationlist.csv with the countrylist.csv to get the full country name for each station number.\n",
    "3. Join the global weather data with the full country names by station number.\n",
    "\n",
    "We can now begin to answer the weather questions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.1 a) Display Schema of global weather dataset table\n",
      "\n",
      "root\n",
      " |-- STN---: string (nullable = true)\n",
      " |-- WBAN: string (nullable = true)\n",
      " |-- YEARMODA: string (nullable = true)\n",
      " |-- TEMP: string (nullable = true)\n",
      " |-- DEWP: string (nullable = true)\n",
      " |-- SLP: string (nullable = true)\n",
      " |-- STP: string (nullable = true)\n",
      " |-- VISIB: string (nullable = true)\n",
      " |-- WDSP: string (nullable = true)\n",
      " |-- MXSPD: string (nullable = true)\n",
      " |-- GUST: string (nullable = true)\n",
      " |-- MAX: string (nullable = true)\n",
      " |-- MIN: string (nullable = true)\n",
      " |-- PRCP: string (nullable = true)\n",
      " |-- SNDP: string (nullable = true)\n",
      " |-- FRSHTT: string (nullable = true)\n",
      "\n",
      "\n",
      "1.1 b) Display contents of global weather dataset table\n",
      "\n",
      "+------+-----+--------+----+----+------+------+-----+----+-----+----+-----+-----+-----+-----+------+\n",
      "|STN---| WBAN|YEARMODA|TEMP|DEWP|   SLP|   STP|VISIB|WDSP|MXSPD|GUST|  MAX|  MIN| PRCP| SNDP|FRSHTT|\n",
      "+------+-----+--------+----+----+------+------+-----+----+-----+----+-----+-----+-----+-----+------+\n",
      "|010260|99999|20190101|26.1|21.2|1001.9| 987.5| 20.6| 9.0| 15.9|29.7| 29.8|21.7*|0.02G| 18.5|001000|\n",
      "|010260|99999|20190102|24.9|22.1|1020.1|1005.5|  5.4| 5.6| 13.6|22.1|27.1*| 20.7|0.48G| 22.8|001000|\n",
      "|010260|99999|20190103|31.7|29.1|1008.9| 994.7| 13.6|11.6| 21.4|49.5|37.4*|26.8*|0.25G|999.9|011000|\n",
      "|010260|99999|20190104|32.9|30.3|1011.4| 997.1| 15.8| 4.9|  7.8|10.9| 36.1| 31.8|0.52G|999.9|001000|\n",
      "|010260|99999|20190105|35.5|33.0|1015.7|1001.4| 12.0|10.4| 13.6|21.0|38.5*| 32.7|0.02G| 23.6|010000|\n",
      "+------+-----+--------+----+----+------+------+-----+----+-----+----+-----+-----+-----+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_wd = spark.read.option(\"header\",True).csv(\"data/2019/*.csv.gz\")\n",
    "\n",
    "print('\\n1.1 a) Display Schema of global weather dataset table\\n')\n",
    "df_wd.printSchema()\n",
    "\n",
    "#Display the contents of global weather data\n",
    "print('\\n1.1 b) Display contents of global weather dataset table\\n')\n",
    "df_wd.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Display Schema of stationlist.csv dataset table\n",
      "\n",
      "root\n",
      " |-- STN_NO: string (nullable = true)\n",
      " |-- COUNTRY_ABBR: string (nullable = true)\n",
      "\n",
      "\n",
      "Display contents of stationlist.csv dataset table\n",
      "\n",
      "+------+------------+\n",
      "|STN_NO|COUNTRY_ABBR|\n",
      "+------+------------+\n",
      "|012240|          NO|\n",
      "|020690|          SW|\n",
      "|020870|          SW|\n",
      "|021190|          SW|\n",
      "|032690|          UK|\n",
      "+------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sl = spark.read.option(\"header\",True).csv(\"stationlist.csv\")\n",
    "print('\\nDisplay Schema of stationlist.csv dataset table\\n')\n",
    "df_sl.printSchema()\n",
    "\n",
    "#Display the contents of station data\n",
    "print('\\nDisplay contents of stationlist.csv dataset table\\n')\n",
    "df_sl.show(5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Display Schema of countrylist.csv dataset table\n",
      "\n",
      "root\n",
      " |-- COUNTRY_ABBR: string (nullable = true)\n",
      " |-- COUNTRY_FULL: string (nullable = true)\n",
      "\n",
      "\n",
      "Display contents of countrylist.csv dataset table\n",
      "\n",
      "+------------+-------------------+\n",
      "|COUNTRY_ABBR|       COUNTRY_FULL|\n",
      "+------------+-------------------+\n",
      "|          AA|              ARUBA|\n",
      "|          AC|ANTIGUA AND BARBUDA|\n",
      "|          AF|        AFGHANISTAN|\n",
      "|          AG|            ALGERIA|\n",
      "|          AI|   ASCENSION ISLAND|\n",
      "+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cl = spark.read.option(\"header\",True).csv(\"countrylist.csv\")\n",
    "print('\\nDisplay Schema of countrylist.csv dataset table\\n')\n",
    "df_cl.printSchema()\n",
    "\n",
    "#Display the contents of countrylist data\n",
    "print('\\nDisplay contents of countrylist.csv dataset table\\n')\n",
    "df_cl.show(5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.2) Display contents of JOIN of stationlist.csv and countrylist.csv dataset tables\n",
      "\n",
      "+------+------------+--------------+\n",
      "|STN_NO|COUNTRY_ABBR|  COUNTRY_FULL|\n",
      "+------+------------+--------------+\n",
      "|012240|          NO|        NORWAY|\n",
      "|020690|          SW|        SWEDEN|\n",
      "|020870|          SW|        SWEDEN|\n",
      "|021190|          SW|        SWEDEN|\n",
      "|032690|          UK|UNITED KINGDOM|\n",
      "|033450|          UK|UNITED KINGDOM|\n",
      "|039290|          UK|UNITED KINGDOM|\n",
      "|039790|          EI|       IRELAND|\n",
      "|040480|          IC|       ICELAND|\n",
      "|041300|          IC|       ICELAND|\n",
      "+------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clsl = df_sl.join(df_cl, df_sl.COUNTRY_ABBR == df_cl.COUNTRY_ABBR, how = 'Left').drop(df_cl.COUNTRY_ABBR)\n",
    "\n",
    "print('\\n1.2) Display contents of JOIN of stationlist.csv and countrylist.csv dataset tables\\n')\n",
    "df_clsl.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.3) Display contents of global weather data and full country names by station number\n",
      "\n",
      "+------+-----+--------+----+----+------+------+-----+----+-----+-----+-----+-----+-----+-----+------+------------+\n",
      "|STN---| WBAN|YEARMODA|TEMP|DEWP|   SLP|   STP|VISIB|WDSP|MXSPD| GUST|  MAX|  MIN| PRCP| SNDP|FRSHTT|COUNTRY_FULL|\n",
      "+------+-----+--------+----+----+------+------+-----+----+-----+-----+-----+-----+-----+-----+------+------------+\n",
      "|010875|99999|20190101|41.1|30.1|9999.9|9999.9|  5.9|46.7| 59.1| 74.0|44.6*|37.4*|99.99|999.9|011010|      NORWAY|\n",
      "|010875|99999|20190102|40.5|29.0|9999.9|9999.9|  6.2|20.5| 32.1| 44.1|41.0*|37.4*|99.99|999.9|010000|      NORWAY|\n",
      "|010875|99999|20190103|43.0|36.6|9999.9|9999.9|  6.1|13.5| 21.0|999.9|44.6*|41.0*|0.00I|999.9|000000|      NORWAY|\n",
      "|010875|99999|20190104|46.7|44.4|9999.9|9999.9|  5.8|27.4| 33.0| 40.0|48.2*|42.8*|99.99|999.9|010000|      NORWAY|\n",
      "|010875|99999|20190105|46.5|44.1|9999.9|9999.9|  6.1|18.3| 25.1|999.9|48.2*|44.6*|99.99|999.9|010000|      NORWAY|\n",
      "+------+-----+--------+----+----+------+------+-----+----+-----+-----+-----+-----+-----+-----+------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3. Join the global weather data with the full country names by station number.\n",
    "df_wdclsl = df_wd.join(df_clsl, df_wd['STN---'] == df_clsl.STN_NO, how = 'Left').drop(\n",
    "    df_clsl['STN_NO']).drop(df_clsl['COUNTRY_ABBR'])\n",
    "\n",
    "print('\\n1.3) Display contents of global weather data and full country names by station number\\n')\n",
    "df_wdclsl.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Questions\n",
    "Using the global weather data, answer the following:\n",
    "\n",
    "1. Which country had the hottest average mean temperature over the year?\n",
    "2. Which country had the most consecutive days of tornadoes/funnel cloud formations?\n",
    "3. Which country had the second highest average mean wind speed over the year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2.1) The country that had the hottest average mean temperature over the year\n",
      "\n",
      "+------------+-----------------+\n",
      "|COUNTRY_FULL|         AVG_TEMP|\n",
      "+------------+-----------------+\n",
      "|    DJIBOUTI|90.06114457831325|\n",
      "+------------+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2p1 = df_wdclsl.groupby('COUNTRY_FULL').agg(F.avg('TEMP').alias('AVG_TEMP')).sort(F.col(\"AVG_TEMP\").desc())\n",
    "\n",
    "print('\\n 2.1) The country that had the hottest average mean temperature over the year\\n')\n",
    "df_2p1.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------+----+----+------+------+-----+-----+-----+-----+-----+-----+-----+-----+------+-------------+\n",
      "|STN---| WBAN|YEARMODA|TEMP|DEWP|   SLP|   STP|VISIB| WDSP|MXSPD| GUST|  MAX|  MIN| PRCP| SNDP|FRSHTT| COUNTRY_FULL|\n",
      "+------+-----+--------+----+----+------+------+-----+-----+-----+-----+-----+-----+-----+-----+------+-------------+\n",
      "|726797|24132|20190616|62.8|49.6|1013.4| 863.4| 10.0|  4.3| 13.0| 29.9| 79.0| 45.0|0.02G|999.9|010011|UNITED STATES|\n",
      "|655280|99999|20191027|80.6|72.8|1009.3| 963.2|  5.0|999.9|999.9|999.9|92.1*| 69.1|0.00I|999.9|000011|COTE D'IVOIRE|\n",
      "|123850|99999|20190521|61.1|56.1|1004.7| 986.7| 15.9|  6.0| 11.7|999.9| 70.9|53.2*|0.80G|999.9|010011|       POLAND|\n",
      "|718432|99999|20190515|32.0|28.2|1007.0|9999.9|  7.4| 13.2| 15.0| 15.9|33.8*|30.2*|99.99|999.9|010001|       CANADA|\n",
      "|718432|99999|20190830|48.7|47.5| 989.9|9999.9|  1.9| 15.8| 18.1| 25.1|50.0*|46.4*|99.99|999.9|010001|       CANADA|\n",
      "+------+-----+--------+----+----+------+------+-----+-----+-----+-----+-----+-----+-----+-----+------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2. Which country had the most consecutive days of tornadoes/funnel cloud formations?\n",
    "\n",
    "df_2p2 = df_wdclsl.filter(F.col('FRSHTT').substr(6, 1) == '1')\n",
    "\n",
    "df_2p2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2p2 = df_2p2.withColumn('DATENUM', F.col('YEARMODA').cast(DoubleType()))\n",
    "\n",
    "w1 = Window.partitionBy(df_2p2.COUNTRY_FULL).orderBy(df_2p2.DATENUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All consecutive dates have same value in column 'diff'\n",
      "\n",
      "+------+-----+--------+----+----+------+------+-----+----+-----+-----+-----+-----+-----+-----+------+------------+-----------+------+-----------+\n",
      "|STN---| WBAN|YEARMODA|TEMP|DEWP|   SLP|   STP|VISIB|WDSP|MXSPD| GUST|  MAX|  MIN| PRCP| SNDP|FRSHTT|COUNTRY_FULL|    DATENUM|row_no|       diff|\n",
      "+------+-----+--------+----+----+------+------+-----+----+-----+-----+-----+-----+-----+-----+------+------------+-----------+------+-----------+\n",
      "|418830|99999|20190822|86.4|79.9|1001.6| 999.6|  2.9| 1.2|  1.9|999.9| 97.5|82.4*|0.04G|999.9|010011|  BANGLADESH|2.0190822E7|     1|2.0190821E7|\n",
      "|477040|99999|20190117|41.1|31.7|9999.9|9999.9|  6.0|13.3| 25.1| 35.9|44.6*|35.6*|99.99|999.9|011111|       JAPAN|2.0190117E7|     1|2.0190116E7|\n",
      "|475730|43318|20190124|35.0|27.6|9999.9|9999.9|  4.9|18.4| 31.1| 41.0|37.4*|32.0*|99.99|999.9|001001|       JAPAN|2.0190124E7|     2|2.0190122E7|\n",
      "|479276|99999|20190302|75.8|69.9|9999.9|9999.9|  5.9|10.0| 15.9|999.9|80.6*|71.6*|99.99|999.9|010001|       JAPAN|2.0190302E7|     3|2.0190299E7|\n",
      "|477940|99999|20190402|42.5|34.1|9999.9|9999.9|  6.2| 9.2| 15.9|999.9|48.2*|33.8*|99.99|999.9|011011|       JAPAN|2.0190402E7|     4|2.0190398E7|\n",
      "+------+-----+--------+----+----+------+------+-----+----+-----+-----+-----+-----+-----+-----+------+------------+-----------+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_2p2.withColumn(\"row_no\", F.row_number().over(w1))\\\n",
    "           .withColumn(\"diff\", F.when(F.isnull(F.col('DATENUM') - F.col('row_no')), 0)\n",
    "                                .otherwise(F.col('DATENUM') - F.col('row_no'))\n",
    "                      )\n",
    "\n",
    "print (\"\\n All consecutive dates have same value in column 'diff'\\n\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GroupBy and Count the values in column 'diff'\n",
      "\n",
      "+------------+-----------+---------------+\n",
      "|COUNTRY_FULL|       diff|num_consecutive|\n",
      "+------------+-----------+---------------+\n",
      "|  BANGLADESH|2.0190821E7|              1|\n",
      "|       JAPAN|2.0190116E7|              1|\n",
      "|       JAPAN|2.0190122E7|              1|\n",
      "|       JAPAN|2.0190299E7|              1|\n",
      "|       JAPAN|2.0190398E7|              1|\n",
      "+------------+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df.groupby('COUNTRY_FULL', 'diff').agg(F.count('*').alias('num_consecutive'))\n",
    "print (\"\\n GroupBy and Count the values in column 'diff'\\n\")  \n",
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GroupBy, find maximum value of column 'num_consecutive' and display sorted result\n",
      "\n",
      "\n",
      " 2.2) The country that had the most consecutive days of tornadoes/funnel cloud formations is: \n",
      "+------------+-------------------+\n",
      "|COUNTRY_FULL|max_num_consecutive|\n",
      "+------------+-------------------+\n",
      "|       ITALY|                  3|\n",
      "+------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df1.groupby('COUNTRY_FULL').agg(F.max('num_consecutive').alias('max_num_consecutive'))\\\n",
    "         .sort(F.col(\"max_num_consecutive\").desc())\n",
    "print (\"\\n GroupBy, find maximum value of column 'num_consecutive' and display sorted result\\n\")\n",
    "print (\"\\n 2.2) The country that had the most consecutive days of tornadoes/funnel cloud formations is: \")\n",
    "\n",
    "df2.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2.3) The country that had the second highest average mean wind speed over the year\n",
      "\n",
      "+------------+--------+\n",
      "|COUNTRY_FULL|AVG_WDSP|\n",
      "+------------+--------+\n",
      "|     ARMENIA|  457.37|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3. Which country had the second highest average mean wind speed over the year?\n",
    "df_2p3 = df_wdclsl.withColumn('WDSPNUM', F.col('WDSP').cast(DoubleType()))\\\n",
    "                  .groupby('COUNTRY_FULL').agg(F.avg('WDSP').alias('AVG_WDSP'))\\\n",
    "                  .withColumn('rn', F.row_number().over(\n",
    "                                                Window.orderBy(F.col(\"AVG_WDSP\").desc())\n",
    "                                                )\n",
    "                             )\\\n",
    "                  .where(F.col('rn') == 2).drop('rn')                             \n",
    "\n",
    "print('\\n 2.3) The country that had the second highest average mean wind speed over the year\\n')\n",
    "df_2p3.select(*['COUNTRY_FULL'], *[F.round(c, 2).alias(c) for c in df_2p3.columns[1:] ]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
